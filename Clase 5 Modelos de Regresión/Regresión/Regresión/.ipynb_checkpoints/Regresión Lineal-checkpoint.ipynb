{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Módulo 5 - Regresión Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "1.Introduccón al dataset \"bikeshare\" \n",
    "* Leyendo los datos\n",
    "* Visualizando los datos\n",
    "\n",
    "2.Regresión lineal\n",
    "* Forma de regresión lineal\n",
    "* Construir un modelo de regresión lineal\n",
    "* Uso del modelo para la predicción\n",
    "* ¿Es importante la escala de las features?\n",
    "\n",
    "3.Trabajando con múltiples features\n",
    "* Visualizando los datos (parte 2)\n",
    "* Agregando más features al modelo\n",
    "\n",
    "4.Eligiendo entre modelos\n",
    "* Selección de features\n",
    "* Métricas de evaluación para problemas de regresión\n",
    "* Comparación de modelos con sets de entrenamiento/test y RMSE\n",
    "* Comparando RMSE de prueba con RMSE nulo (baseline)\n",
    "       \n",
    "5.Creando features\n",
    "* Manejo de feactures categóricas\n",
    "* Ingeniería de features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**===========================================================================================**\n",
    "\n",
    "### 1.1 Importando datos\n",
    "\n",
    "Vamos a trabajar con un conjunto de datos sobre alquileres de bicicletas que fue utilizado en un concurso de Kaggle\n",
    "\n",
    "\n",
    "Se proporcionan datos de alquiler por hora que abarcan dos años. El conjunto de entrenamiento se compone de los primeros 19 días de cada mes, mientras que el conjunto de test es del día 20 al final del mes. **_Queremos predecir el número total de bicicletas alquiladas durante cada hora cubierta por el conjunto de test, utilizando sólo la información disponible en el set de entrenamiento._**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CAMPOS DEL SET**\n",
    "\n",
    "**datetime** - hourly date + timestamp\n",
    "\n",
    "**season** -  1 = winter, 2 = spring, 3 = summer, 4 = fall\n",
    "\n",
    "**holiday** - whether the day is considered a holiday\n",
    "\n",
    "**workingday** - whether the day is neither a weekend nor holiday\n",
    "\n",
    "**weather** - \n",
    "\n",
    "              1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "              2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "              3: Light Snow, Light Rain + Thunderstorm + Scattered clouds,\n",
    "                 Light Rain + Scattered clouds\n",
    "              4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n",
    "\n",
    "**temp** - temperature in Celsius\n",
    "\n",
    "**atemp** - \"feels like\" temperature in Celsius\n",
    "\n",
    "**humidity** - relative humidity\n",
    "\n",
    "**windspeed** - wind speed\n",
    "\n",
    "**casual** - number of non-registered user rentals initiated\n",
    "\n",
    "**registered** - number of registered user rentals initiated\n",
    "\n",
    "**count** - number of total rentals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos los datos y seteamos el datetime como índice.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "bikes = pd.read_csv('train.csv',index_col='datetime', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preguntas:**\n",
    "\n",
    "*     ¿Qué representa cada observación?\n",
    "*     ¿Cuál es la variable de respuesta?\n",
    "*     ¿Cuántas variables hay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.rename(columns={'count':'total'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Definimos parámetros globales para matplotlib.\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste con Seaborn (modelo lineal) \n",
    "sns.lmplot(x='atemp', y='total', data=bikes, aspect=1.45, scatter_kws={'alpha':0.2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste con Seaborn (modelo lineal) \n",
    "sns.lmplot(x='atemp', y='total', data=bikes, aspect=1.45, scatter_kws={'alpha':0.2})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Repaso: forma del modelo lineal\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n$\n",
    "- $y$ es la variable dependiente (es la respuesta)\n",
    "- $\\beta_0$ es el término de intercepción\n",
    "- $\\beta_1$ es el coeficiente para $x_1$ \n",
    "- $\\beta_n$ es el coeficiente para $x_n$\n",
    "\n",
    "Los **$\\beta$** son los llamados **_Coeficientes del modelo_**\n",
    "\n",
    "- Estos valores son estimados (o \"aprendidos\") durante el proceso de adaptación del modelo usando el criterio **mínimos cuadrados**.\n",
    "- Específicamente, encontramos la línea (matemáticamente) que minimiza la suma **de cuadrados de residuos** (o \"suma de errores cuadráticos\").\n",
    "- Y una vez que hemos aprendido estos coeficientes, podemos usar el modelo para predecir la respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Construyendo el modelo de Regresión Lineal\n",
    "\n",
    "Empezamos por una regresión lineal simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos X e y\n",
    "\n",
    "feature_cols = ['temp']\n",
    "X = bikes[feature_cols]\n",
    "y = bikes.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos paquete, instanciamos el estimador y fiteamos el modelo (\"classic\" sklearn!)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos coeficientes\n",
    "\n",
    "print (linreg.intercept_)\n",
    "print (linreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretación del parámetro de **intercepción** ($\\beta_0$):\n",
    "\n",
    "- Es el valor de $ y $ cuando $ x $ = 0.\n",
    "- Por lo tanto, es el número estimado de alquileres cuando la temperatura es de 0 grados Celsius.\n",
    "- **Nota:** No siempre tiene sentido interpretar la intercepción. (¿Por qué?)\n",
    "\n",
    "Interpretación del coeficiente de **\"temp\"** ($\\beta_1$):\n",
    "\n",
    "- Es el cambio en $ y $ dividido por cambio en $ x $, o la \"pendiente\".\n",
    "- Así, un aumento de la temperatura de 1 grado Celsius es **asociado con** un aumento de alquiler de 9.17 bicicletas.\n",
    "- No se trata de una declaración de causalidad.\n",
    "- $ \\beta_1 $ sería **negativo** si un aumento en la temperatura se asocia con una **disminución** en los alquileres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Usando el modelo para predecir\n",
    "\n",
    "¿Cuántos alquileres de bicicletas podríamos predecir si la temperatura era de 25 grados Celsius?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando la fórmula manualmente\n",
    "grados_celsius = 25\n",
    "linreg.intercept_ + linreg.coef_ * grados_celsius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando el método del objeto\n",
    "grados_celsius = np.array(25).reshape(-1,1)\n",
    "linreg.predict(grados_celsius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sumando más features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos lista de features\n",
    "\n",
    "feature_cols = ['temp', 'season', 'weather', 'humidity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos nuevamente X and y\n",
    "X = bikes[feature_cols]\n",
    "y = bikes.total\n",
    "\n",
    "# creamos el modelo y fiteamos\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n",
    "\n",
    "# Imprimimos coeficientes\n",
    "print (linreg.intercept_)\n",
    "print (linreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (linreg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.groupby('season')['total'].sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## para observarlo mejor miramos el nombre con el coeficiente\n",
    "list(zip(feature_cols, linreg.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretación de los coeficientes:\n",
    "\n",
    "- Manteniendo todas las demás características fijas, un incremento de 1 unidad en **la temperatura** se asocia con un **aumento de alquiler de 7.86 bicicletas**.\n",
    "- Manteniendo todas las demás características fijas, un aumento de 1 unidad en **temporada** se asocia con un **aumento de alquiler de 22,5 bicicletas**.\n",
    "- Manteniendo todas las demás características fijas, un incremento de 1 unidad en **tiempo** se asocia con un **aumento de alquiler de 6,67 bicicletas**.\n",
    "- Manteniendo todas las otras características fijas, un aumento de 1 unidad en **humedad** se asocia con una **disminución de alquiler de 3.12 bicicletas**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Métricas de evaluación para problemas de regresión\n",
    "\n",
    "Las métricas de evaluación para problemas de clasificación, como **precisión**, no son útiles para problemas de regresión. Necesitamos métricas de evaluación diseñadas para comparar **valores continuos**. En las próximas clases trabajaremos más en profundidad sobre estas métricas e iremos viendo detalles de su implementación en `python`.\n",
    "\n",
    "Aquí hay tres métricas de evaluación comunes para problemas de regresión:\n",
    "\n",
    "**El error absoluto medio** (MAE) es la media del valor absoluto de los errores:\n",
    "\n",
    "$$ \\frac 1n\\sum_ {i = 1}^n |y_i-\\hat{y}_i| $$\n",
    "\n",
    "**Mean Squared Error** (MSE) es la media de los errores al cuadrado:\n",
    "\n",
    "$$ \\frac 1n\\sum_ {i = 1}^n(y_i- \\hat{y}_i)^2 $$\n",
    "\n",
    "**Error cuadrático medio raíz** (RMSE) es la raíz cuadrada de la media de los errores al cuadrado:\n",
    "\n",
    "$$ \\sqrt{\\frac 1n\\sum_{i = 1}^n(y_i- \\hat{y}_i)^2} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando estas métricas:\n",
    "\n",
    "- **MAE** es el más fácil de entender, porque es el error promedio.\n",
    "- **MSE** es más popular que MAE, porque MSE \"penaliza\" errores grandes, y eso tiende a ser útil en el mundo real.\n",
    "- **RMSE** es aún más popular que MSE, porque RMSE es interpretable en las unidades \"y\".\n",
    "- **$R^2$** es la proporción de la varianza total de $Y$ explicada por el modelo.\n",
    "\n",
    "Todas estas son **funciones de pérdida**, porque queremos minimizarlas.\n",
    "\n",
    "Ejemplo adicional, para ver cómo MSE / RMSE penalizan más a los errores más grandes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Comparando modelos usando sets de entrenamiento/test y RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Definimos una función que acepta una lista de features y devuelve la prueba RMSE\n",
    "\n",
    "def train_test_rmse(feature_cols):\n",
    "    X = bikes[feature_cols]\n",
    "    y = bikes.total\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=986322)\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_pred = linreg.predict(X_test)\n",
    "    return ({'RMSE':np.sqrt(metrics.mean_squared_error(y_test, y_pred)),'R2':metrics.r2_score(y_test, y_pred)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparamos diferentes ensambles de features\n",
    "print(train_test_rmse(['temp']))\n",
    "print(train_test_rmse(['temp', 'season', 'weather', 'humidity']))\n",
    "print(train_test_rmse(['temp', 'season', 'weather']))\n",
    "print(train_test_rmse(['temp', 'season', 'humidity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 Comparar RMSE de Modelo con RMSE nulo (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos X e y para el set de entrenemiento y el de test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)\n",
    "\n",
    "# creamos un array numpy con la misma forma que y_test\n",
    "\n",
    "y_null = np.zeros_like(y_test, dtype=float)\n",
    "\n",
    "# rellenamos el array con el valor medio de y_test\n",
    "\n",
    "y_null.fill(y_test.mean())\n",
    "y_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculamos RMSE\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_null))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R2:',train_test_rmse(['temp']))\n",
    "print('R2:',train_test_rmse(['temp', 'season', 'weather', 'humidity']))\n",
    "print('R2:',train_test_rmse(['temp', 'season', 'weather']))\n",
    "print('R2:',train_test_rmse(['temp', 'season', 'humidity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Manejo de características categóricas\n",
    "\n",
    "Scikit-learn espera que todas las funciones sean numéricas. Entonces, ¿cómo incluimos una característica categórica en nuestro modelo?\n",
    "\n",
    "- **Categorías ordenadas:** transformarlas en valores numéricos sensibles (ejemplo: pequeño = 1, medio = 2, grande = 3)\n",
    "- **Categorías no ordenadas:** utilizar codificación ficticia (0/1) (Variables-dummy)\n",
    "\n",
    "¿Cuáles son las características categóricas de nuestro conjunto de datos?\n",
    "\n",
    "- **Categorías ordenadas:** weather (ya codificado con valores numéricos sensibles)\n",
    "- **Categorías no ordenadas:** season (necesita variables dummy), holiday (Ya está codificada como dummy), workingday (ya está codificada como dummy)\n",
    "\n",
    "Para la temporada, no podemos simplemente dejar la codificación como 1 = primavera, 2 = verano, 3 = otoño y 4 = invierno, porque eso implicaría una **relación ordenada**. En cambio, creamos **variables dummys múltiples:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear variables dummies\n",
    "season_dummies = pd.get_dummies(bikes.season, prefix='season')\n",
    "\n",
    "# imprimimos para ver 5 filas cualquieras\n",
    "season_dummies.sample(n=5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, en realidad sólo necesitamos ** tres variables dummy (no cuatro) **, y por lo tanto vamos a dejar caer la primera variable dummy.\n",
    "\n",
    "¿Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salteamos la primer columna\n",
    "season_dummies.drop(season_dummies.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# imprimimos 5 filas cualquieras\n",
    "season_dummies.sample(n=5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, si se tiene una feature categórica con ** k valores posibles **, se tienen que crear ** k-1 variables ficticias **."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar el DataFrame original y el dummy DataFrame (axis = 0 significa filas, axis = 1 significa columnas)\n",
    "bikes = pd.concat([bikes, season_dummies], axis=1)\n",
    "\n",
    "# imprimimos 5 filas cualquieras\n",
    "bikes.sample(n=5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incluímos variables dummies\n",
    "\n",
    "feature_cols = ['temp','season_2', 'season_3', 'season_4','humidity']\n",
    "X = bikes[feature_cols]\n",
    "y = bikes.total\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n",
    "\n",
    "list(zip(feature_cols, linreg.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> ¿Cómo interpretamos los coeficientes de season?¿Piensan que es coherente?\n",
    "\n",
    "\n",
    "**los season se miden con respecto a la línea de base (winter)**:\n",
    "\n",
    "- Manteniendo todas las demás características fijas, **spring** se asocia con un **decremento de alquiler de 3.39 bicicletas** en comparación con winter.\n",
    "- Manteniendo todas las demás características fijas, **summer** se asocia con una **disminución de alquiler de 41,7 bicicletas** en comparación con winter.\n",
    "- Manteniendo todas las demás características fijas, **fall** se asocia con un **aumento de alquiler de 64,4 bicicletas** en comparación con winter.\n",
    "\n",
    "¿Qué pasa si cambiamos la dummy que se definió como la línea de base? ¿Cambiarían los efectos?\n",
    "\n",
    "- No, simplemente cambiaría nuestra **interpretación** de los coeficientes.\n",
    "\n",
    "**Importante:** La codificación por dummies es relevante para todos los modelos de aprendizaje automático, no sólo para los modelos de regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparar modelo con la feature season contra modelo con variables dummy.\n",
    "\n",
    "print (train_test_rmse(['temp', 'season', 'humidity']))\n",
    "print (train_test_rmse(['temp', 'season_2', 'season_3', 'season_4', 'humidity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Conclusiones: Comparación de la regresión lineal con otros modelos\n",
    "\n",
    "Ventajas de la regresión lineal:\n",
    "\n",
    "- Simple de explicar\n",
    "- Muy interpretable\n",
    "- El entrenamiento y predicción de modelos son rápidos\n",
    "- No se requiere ajuste (excluyendo la regularización)\n",
    "- Las features no necesitan escala\n",
    "- Puede funcionar bien con un pequeño número de observaciones\n",
    "\n",
    "Desventajas de la regresión lineal:\n",
    "\n",
    "- Presume una relación lineal entre las features y la respuesta\n",
    "- El rendimiento es (generalmente) no competitivo con los mejores métodos de aprendizaje supervisado debido a un alto sesgo"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
